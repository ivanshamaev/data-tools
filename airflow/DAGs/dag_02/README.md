# orchestrator_seq_dag — README

Цель: DAG получает список дат из MSSQL, берёт первые N дат (N задаётся через `dag_run.conf['n']`) и последовательно (строго одна за другой, от большей к меньшей) триггерит другой даг для каждой из этих N дат. Оставшиеся даты отправляются в MSSQL как отдельные вызовы хранимой процедуры `EXEC Procedure '<date>'` также последовательно.

Файлы в папке:
- `orchestrator_seq_dag.py` — реализация дага
- `README.md` — этот файл

Краткая логика дага
1. `get_dates()` — task (TaskFlow) выполняет SQL запрос к MSSQL и возвращает список дат в формате `YYYY-MM-DD`, отсортированных по убыванию (самые новые первыми). Это TaskFlow возвращает список через XCom.
2. `orchestrate(dates)` — task (TaskFlow) получает список дат, читает параметр `n` из `dag_run.conf`, делит список на `top` (первые N) и `rest` (остальные). Затем:
   - для каждой даты из `top` последовательно вызывает `trigger_dag(...)` (Airflow API) — это создаёт DagRun целевого дага для каждой даты, последовательность соблюдается потому, что код вызывает `trigger_dag` в цикле и ждёт перед вызовом следующего (не создаются параллельные триггеры);
   - для каждой даты из `rest` последовательно выполняет SQL `EXEC Procedure '<date>'` через `MsSqlHook.run()`.
3. Результат (`{'triggered': [...], 'executed': [...]}`) возвращается в XCom для отладки.

Пояснения для младшего разработчика (пошагово)

- Почему мы используем TaskFlow (`@task`) вместо обычных операторов?
  - TaskFlow удобнее для передачи данных между тасками (через возврат и XCom). Код становится короче и понятнее: одна функция = один таск.

- Как читается параметр `n` и зачем он нужен?
  - `n` принимается из `dag_run.conf`, это конфигурация, которую вы передаёте при триггере дага (CLI, UI, API). Пример: `airflow dags trigger --conf '{"n": 3}' orchestrator_seq_dag`.
  - `n` говорит, сколько первых (самых больших) дат нужно использовать для триггеров другого дага.

- Почему порядок важен и как мы его обеспечиваем?
  - В SQL мы делаем `ORDER BY date_col DESC`, поэтому `get_dates()` возвращает даты от самой новой к самой старой. Затем внутри `orchestrate` мы итерируем `top` в этом порядке — это гарантирует последовательность от большой к меньшей.

- Как сделать триггеры строго последовательными?
  - Мы используем простую последовательную логику в Python: for d in top: trigger_dag(...); sleep(optional). Так как это один таск, вызовы идут один за другим и не запускаются параллельно. Если вы хотите дождаться полного завершения каждого запущенного дага — это отдельная задача (нужно опрашивать состояние `DagRun` или использовать `TriggerDagRunOperator` с `wait_for_completion=True`).

- Почему используем `trigger_dag` из `airflow.api.common.experimental.trigger_dag`?
  - Это удобная функция, которая создаёт запись `DagRun` в базе. Мы вызываем её программно из Python-кода, чтобы создать запуски целевого дага. Это приемлемо для orchestration-логики, где мы хотим жестко контролировать порядок запуска.

- Почему мы не создаём отдельные Airflow таски для каждого триггера?
  - Нельзя заранее знать `n` (оно приходит в `dag_run.conf`) и список дат может быть длинным/динамичным. Создание тасков во время runtime (dynamic task creation outside mapping) не поддерживается. Поэтому удобный и контролируемый способ — последовательный триггер внутри одного таска.

- Как выполняются SQL вызовы для оставшихся дат?
  - Мы используем `MsSqlHook.run(sql)` в цикле. Это выполняет SQL последовательно.

- Что про ошибки и ретраи?
  - Вся последовательная логика находится в одном таске (`orchestrate`). Если там произойдёт исключение, таск упадёт и будет происходить retry согласно конфигурации дага/таска. Это значит: в случае частичного выполнения (например, 3 из 5 прошли) при ретраи таск начнёт с начала. Если нужно реализовать более тонкую идемпотентную логику (чтобы не повторять уже выполненные шаги), добавьте запись успешных шагов в таблицу состояния или используйте external id-переменные.

- Безопасность и параллельность
  - Так как мы делаем последовательные вызовы, мы не создаём параллельных нагрузок на целевой даг или базу. Но если `top` велик, общее время выполнения таска может быть долгим и превысить таймауты. Оценивайте время и, при необходимости, делайте batching.

- Примеры запуска
  - Триггер через CLI с тремя первыми датами:

```bash
airflow dags trigger --conf '{"n": 3}' orchestrator_seq_dag
```

Файлы: `orchestrator_seq_dag.py` — [DAGs/dag_02/orchestrator_seq_dag.py](DAGs/dag_02/orchestrator_seq_dag.py)

