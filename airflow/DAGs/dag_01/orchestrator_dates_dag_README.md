# orchestrator_dates_dag — README

Кратко: DAG получает список дат из MSSQL, берёт первые N дат (N задаётся через `dag_run.conf['n']`), для первых N дат триггерит другой даг (`TARGET_DAG_ID`) — по одному запуску на дату; для оставшихся дат выполняет вызов хранимой процедуры в MSSQL вида `EXEC Procedure '<date>'` (по одной задаче на дату).

Файл дага: [DAGs/orchestrator_dates_dag.py](DAGs/orchestrator_dates_dag.py)

Основные шаги выполнения:
- Получение дат: функция `get_dates()` использует `MsSqlHook.get_records()` и возвращает список дат в формате `YYYY-MM-DD`.
- Разбиение: `split_dates()` берёт параметр `n` из `dag_run.conf` и делит список на `top` (первые N) и `rest` (остальное).
- Триггер для первых N: `TriggerDagRunOperator.partial(...).expand(conf=[...])` — создаёт по одному mapped-запуску, каждый с `conf={'date': <дата>}`.
- Выполнение процедуры для оставшихся: `MsSqlOperator.partial(...).expand(sql=[...])` — создаёт по одному mssql task на каждую дату и выполняет `EXEC Procedure '<date>'`.

Пояснения по ключевым моментам

- Что делает `partial` и `expand`?
  - `partial()` создаёт частично сконфигурированный экземпляр оператора, который можно затем «развернуть» с помощью `expand()` — это механизм Task Mapping (Airflow 2.3+).
  - `expand(...)` принимает аргументы в виде списков (или списка словарей через `expand_kwargs`) и создаёт по одному mapped task для каждого элемента списка. В нашем даге `expand(conf=[{'date': d} for d in parts['top']])` создаст N mapped tasks, каждый с `conf` соответствующей даты.
  - Как управлять `expand`:
    - Количество создаваемых тасков == длине списка(ов), переданных в `expand` (для элемент-wise mapping все списки должны иметь одинаковую длину). Для списка словарей (`expand(conf=[...])`) длина списка = число запусков.
    - Параметры параллельности контролируются глобальными и локальными настройками Airflow: `max_active_tasks`, `parallelism`, `pools`, `concurrency` и `task_concurrency`.

- Зачем `EmptyOperator` (`start`, `end`)?
  - Просто маркеры/синхронизаторы в графе, чтобы сделать зависимости и визуализацию понятнее. Они не выполняют работу, но позволяют удобно ставить точки входа/выхода и группировать зависимости.

- Что значит `isinstance(val, (datetime, date))`?
  - Это стандартная проверка Python: проверяет, является ли `val` экземпляром `datetime.datetime` или `datetime.date`. Если да — мы форматируем его через `.strftime('%Y-%m-%d')`, иначе просто приводим к `str`. Это важно, потому что драйвер базы может вернуть `date` или `datetime`.

- Почему не вызывать `operator.execute()` вручную внутри `execute()` другой задачи?
  - Вызов `execute()` напрямую не создаёт таску в графе, не учитывается планировщиком, не даёт отдельной видимости в UI и ломает ретраи/логирование/метрики. Вместо этого используйте генерацию задач при парсинге DAG или Task Mapping (`expand`) для создания отдельных тасков.

- Про `TriggerDagRunOperator` и `wait_for_completion`:
  - В нашем даге `wait_for_completion=False`, значит триггер идёт асинхронно: текущие mapped-таски быстро завершатся после отправки триггера. Если нужно дождаться завершения целевого дага, можно включить `wait_for_completion=True` и настроить `allowed_states`/`failed_states` и таймаут.

- Работа с `dag_run.conf` и пример запуска:
  - Параметр `n` ожидается в `dag_run.conf`, например при CLI-триггере:

```bash
airflow dags trigger --conf '{"n": 3}' orchestrator_dates_dag
```

- Требования и настройки:
  - Airflow 2.3+ (для Task Mapping и `.expand()`);
  - Установлен провайдер `apache-airflow-providers-microsoft-mssql`;
  - Создана connection с id, указанным в `DEFAULT_CONN_ID` (по умолчанию `mssql_default`);
  - Указать реальные `your_schema.your_table` и `date_col`, `TARGET_DAG_ID` и, при необходимости, имя процедуры в SQL для `MsSqlOperator`.

- Ограничения и замечания:
  - Вызов большого количества mapped tasks создаст множество параллельных операций (и триггеров запуска целевого дага). Контролируйте через пулы или `max_active_runs`/`concurrency`.
  - Если порядок важен (в нашем даге мы берём даты в порядке убывания в SQL), убедитесь, что `ORDER BY` корректен и формат дат соответствует ожиданию.
  - Если нужно, чтобы список дат генерировался во время выполнения и сразу же породил динамические задачи — можно использовать паттерн: задача A вычисляет список и кладёт в XCom; задача B затем делает `.expand()` через получение XCom (TaskFlow позволяет pull XCom внутри mapped context). В текущей реализации оба шага выполняются в одном даге через TaskFlow.

Файл дага: [DAGs/orchestrator_dates_dag.py](DAGs/orchestrator_dates_dag.py)

